#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --cpus-per-task=16
#SBATCH --job-name=new_coco_img2text_aligner
#SBATCH --output=/home/azywot/FOMO/stable-diffusion-v2/outputs/jobs/coco_img2text_aligner_%A.out
#SBATCH --time=14:00:00
#SBATCH --mem=80G
#SBATCH --hint=nomultithread

echo "âœ… Job started at: $(date)"
module purge
module load 2023
module load Anaconda3/2023.07-2
module load CUDA/12.1.1

# conda env create -f environment.yaml
source activate ldmv2
# Install through conda, otherwise wont work on H100!
# conda install pytorch torchvision=0.18.1 pytorch-cuda=12.1 -c pytorch -c nvidia -y

# Confirm install
python -c "import torch; print(f'ðŸ”§ Torch: {torch.__version__}, CUDA: {torch.version.cuda}, Arch: {torch.cuda.get_device_capability()}')"

# Set Hugging Face cache directories
export HF_DATASETS_CACHE="/scratch-shared/holy-triangle/huggingface_datasets"
export TRANSFORMERS_CACHE="/scratch-shared/holy-triangle/huggingface_models"

# TODO: add --exclude_cls!
# Train using cosine similarity loss
echo "ðŸš€ Training with cosine similarity loss..."
python scripts/vcf/train_img2text_aligner.py \
  --datasets coco \
  --loss cosine \
  --batch_size 256 \
  --epochs 10 \
  --lr 1e-4 \
  --device cuda \
  --model_path weights/img2text_aligner/coco_cosine/model.pth \
  --save_every 2

# TODO: add --exclude_cls!
# Train using InfoNCE loss
echo "ðŸš€ Training with InfoNCE loss..."
python scripts/vcf/train_img2text_aligner.py \
  --datasets coco \
  --loss infonce \
  --batch_size 256 \
  --epochs 10 \
  --lr 1e-4 \
  --device cuda \
  --model_path weights/img2text_aligner/coco_infonce/model.pth \
  --save_every 2

echo "âœ… Job completed at: $(date)"
echo "ðŸ”š All done!"