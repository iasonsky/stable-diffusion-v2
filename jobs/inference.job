#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --cpus-per-task=8
#SBATCH --job-name=sd2_aligner_inference
#SBATCH --output=RunMethod_%A_h100_inference_job_conditioning_schedule_0102.out
#SBATCH --time=00:10:00
#SBATCH --mem=40G
#SBATCH --hint=nomultithread

echo "âœ… Job started at: $(date)"
module purge
module load 2023
module load Anaconda3/2023.07-2
module load CUDA/12.1.1

# Activate Conda environment
source activate ldmv2

conda install pytorch torchvision=0.18.1 pytorch-cuda=12.1 -c pytorch -c nvidia -y

python -c "import torch; print(f'ðŸ”§ Torch: {torch.__version__}, CUDA: {torch.version.cuda}, Arch: {torch.cuda.get_device_capability()}')"

pip install git+https://github.com/openai/CLIP.git

# python ../scripts/txt2img.py \
#   --prompt "a photo of a cat" \
#   --ckpt "checkpoints/model_checkpoint.ckpt" \
#   --config ../configs/stable-diffusion/v2-inference-v.yaml \
#   --H 768 --W 768 \
#   --ref_img "data/cat.jpg" \
#   --aligner_model_path "./weights/aligner_models/version_v1/dataset_flickr30k/loss_infonce/batch_64/stable-diffusion-2-1/model_best.pth" \
#   --ref_blend_weight 1.0 \
#   --fusion_token_type "all" \
#   --use_cross_attention_fusion \
#   --use_ref_img \
#   --timestep_cond_start 0.0 \
#   --timestep_cond_end 0.5

python scripts/txt2img.py \
  --prompt "a photo of a cat" \
  --ckpt "checkpoints/model_checkpoint.ckpt" \
  --config configs/stable-diffusion/v2-inference-v.yaml \
  --H 768 --W 768 \
  --ref_img "data/cat.jpg" \
  --ref_blend_weight 0.1 \
  --aligner_version v1 \
  --aligner_dataset flickr30k \
  --aligner_loss infonce \
  --fusion_token_type all \
  --fusion_type alpha_blend \
  --calculate_clip_score \
  --timestep_cond_start 0.0 \
  --timestep_cond_end 1.0 \
  --amplify_image_features


echo "âœ… Inference job completed at: $(date)"
